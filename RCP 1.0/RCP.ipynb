{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class handDetector():\n",
    "    def __init__(self, mode = False, maxHands = 6, modelComplex = 1, detectionCon = 0.5, trackCon = 0.5):\n",
    "        self.mode = mode\n",
    "        self.maxHands = maxHands\n",
    "        self.modelComplex = modelComplex\n",
    "        self.detectionCon = detectionCon\n",
    "        self.trackCon = trackCon\n",
    "\n",
    "        self.mpHands = mp.solutions.hands\n",
    "        self.hands = self.mpHands.Hands(self.mode, self.maxHands, self.modelComplex, self.detectionCon, self.trackCon)\n",
    "        self.mpDraw = mp.solutions.drawing_utils\n",
    "        \n",
    "    def findHands(self,img, draw = True):\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        self.results = self.hands.process(imgRGB)\n",
    "        # print(results.multi_hand_landmarks)\n",
    "\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            for handLms in self.results.multi_hand_landmarks:\n",
    "                if draw:\n",
    "                    self.mpDraw.draw_landmarks(img, handLms, self.mpHands.HAND_CONNECTIONS)\n",
    "        return img\n",
    "\n",
    "#     def findPosition(self, img, handNo = 0, draw = True):\n",
    "\n",
    "#         lmlist = []\n",
    "#         hand_count = 0\n",
    "#         if self.results.multi_hand_landmarks:\n",
    "#             for hand in self.results.multi_hand_landmarks:\n",
    "#                 hand_count += 1\n",
    "#             myHand = self.results.multi_hand_landmarks[hand_count-1]\n",
    "#             for id, lm in enumerate(myHand.landmark):\n",
    "#                 h, w, c = img.shape\n",
    "#                 cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "#                 lmlist.append([id, cx, cy])\n",
    "#                 if draw:\n",
    "#                     cv2.circle(img, (cx, cy), 3, (255, 0, 255), cv2.FILLED)\n",
    "#         return lmlist, hand_count\n",
    "    \n",
    "    def findPosition(self, img, handNo = 0, draw = True):\n",
    "\n",
    "        all_lmlist = []\n",
    "        hand_count = 0\n",
    "        if self.results.multi_hand_landmarks:\n",
    "            for hand in self.results.multi_hand_landmarks:\n",
    "                hand_count += 1\n",
    "                lmlist = []\n",
    "                myHand = self.results.multi_hand_landmarks[hand_count-1]\n",
    "                for id, lm in enumerate(myHand.landmark):\n",
    "                    h, w, c = img.shape\n",
    "                    cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "                    lmlist.append([id, cx, cy])\n",
    "                    if draw:\n",
    "                        cv2.circle(img, (cx, cy), 3, (255, 0, 255), cv2.FILLED)\n",
    "                all_lmlist.append(lmlist)\n",
    "        return all_lmlist, hand_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp: 10:47:13.938131\n",
      "number of hands detected: 1\n",
      "hand coordinates [707, 522]\n",
      "\n",
      "\n",
      "timestamp: 10:47:14.031827\n",
      "number of hands detected: 2\n",
      "hand coordinates [445, 447]\n",
      "hand coordinates [710, 498]\n",
      "\n",
      "\n",
      "timestamp: 10:47:14.134355\n",
      "number of hands detected: 2\n",
      "hand coordinates [475, 456]\n",
      "hand coordinates [698, 507]\n",
      "\n",
      "\n",
      "timestamp: 10:47:14.227265\n",
      "number of hands detected: 2\n",
      "hand coordinates [499, 468]\n",
      "hand coordinates [690, 512]\n",
      "\n",
      "\n",
      "timestamp: 10:47:14.332419\n",
      "number of hands detected: 2\n",
      "hand coordinates [521, 477]\n",
      "hand coordinates [688, 501]\n",
      "\n",
      "\n",
      "timestamp: 10:47:14.427098\n",
      "number of hands detected: 2\n",
      "hand coordinates [537, 461]\n",
      "hand coordinates [675, 493]\n",
      "\n",
      "\n",
      "timestamp: 10:47:14.494177\n",
      "number of hands detected: 2\n",
      "hand coordinates [550, 453]\n",
      "hand coordinates [673, 481]\n",
      "\n",
      "\n",
      "timestamp: 10:47:14.564754\n",
      "number of hands detected: 2\n",
      "hand coordinates [555, 445]\n",
      "hand coordinates [666, 476]\n",
      "\n",
      "\n",
      "timestamp: 10:47:14.662277\n",
      "number of hands detected: 2\n",
      "hand coordinates [565, 442]\n",
      "hand coordinates [649, 470]\n",
      "\n",
      "\n",
      "timestamp: 10:47:14.733208\n",
      "number of hands detected: 2\n",
      "hand coordinates [565, 444]\n",
      "hand coordinates [639, 473]\n",
      "\n",
      "\n",
      "timestamp: 10:47:14.828532\n",
      "number of hands detected: 2\n",
      "hand coordinates [570, 443]\n",
      "hand coordinates [629, 473]\n",
      "\n",
      "\n",
      "timestamp: 10:47:14.931170\n",
      "number of hands detected: 2\n",
      "hand coordinates [566, 449]\n",
      "hand coordinates [616, 480]\n",
      "\n",
      "\n",
      "timestamp: 10:47:15.030617\n",
      "number of hands detected: 2\n",
      "hand coordinates [547, 427]\n",
      "hand coordinates [623, 476]\n",
      "\n",
      "\n",
      "timestamp: 10:47:15.131972\n",
      "number of hands detected: 2\n",
      "hand coordinates [526, 411]\n",
      "hand coordinates [645, 464]\n",
      "\n",
      "\n",
      "timestamp: 10:47:15.226505\n",
      "number of hands detected: 2\n",
      "hand coordinates [504, 398]\n",
      "hand coordinates [674, 455]\n",
      "\n",
      "\n",
      "timestamp: 10:47:15.331004\n",
      "number of hands detected: 2\n",
      "hand coordinates [471, 377]\n",
      "hand coordinates [689, 453]\n",
      "\n",
      "\n",
      "timestamp: 10:47:15.426386\n",
      "number of hands detected: 2\n",
      "hand coordinates [441, 368]\n",
      "hand coordinates [707, 438]\n",
      "\n",
      "\n",
      "timestamp: 10:47:15.492471\n",
      "number of hands detected: 2\n",
      "hand coordinates [428, 359]\n",
      "hand coordinates [718, 426]\n",
      "\n",
      "\n",
      "timestamp: 10:47:15.560019\n",
      "number of hands detected: 2\n",
      "hand coordinates [413, 355]\n",
      "hand coordinates [730, 408]\n",
      "\n",
      "\n",
      "timestamp: 10:47:15.627160\n",
      "number of hands detected: 2\n",
      "hand coordinates [401, 356]\n",
      "hand coordinates [764, 392]\n",
      "\n",
      "\n",
      "timestamp: 10:47:15.725904\n",
      "number of hands detected: 2\n",
      "hand coordinates [379, 358]\n",
      "hand coordinates [800, 389]\n",
      "\n",
      "\n",
      "timestamp: 10:47:15.793793\n",
      "number of hands detected: 2\n",
      "hand coordinates [362, 368]\n",
      "hand coordinates [826, 388]\n",
      "\n",
      "\n",
      "timestamp: 10:47:15.893818\n",
      "number of hands detected: 2\n",
      "hand coordinates [334, 380]\n",
      "hand coordinates [846, 402]\n",
      "\n",
      "\n",
      "timestamp: 10:47:15.962948\n",
      "number of hands detected: 2\n",
      "hand coordinates [310, 392]\n",
      "hand coordinates [857, 413]\n",
      "\n",
      "\n",
      "timestamp: 10:47:16.058354\n",
      "number of hands detected: 2\n",
      "hand coordinates [269, 419]\n",
      "hand coordinates [889, 439]\n",
      "\n",
      "\n",
      "timestamp: 10:47:16.128621\n",
      "number of hands detected: 2\n",
      "hand coordinates [246, 449]\n",
      "hand coordinates [904, 456]\n",
      "\n",
      "\n",
      "timestamp: 10:47:16.224463\n",
      "number of hands detected: 2\n",
      "hand coordinates [252, 525]\n",
      "hand coordinates [922, 515]\n",
      "\n",
      "\n",
      "timestamp: 10:47:16.295373\n",
      "number of hands detected: 2\n",
      "hand coordinates [274, 691]\n",
      "hand coordinates [902, 668]\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/r_/36_vmnld25d6v2jd0n4yygjm0000gn/T/ipykernel_27903/43391966.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindHands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mall_lmlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhand_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindPosition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_lmlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/r_/36_vmnld25d6v2jd0n4yygjm0000gn/T/ipykernel_27903/1209540876.py\u001b[0m in \u001b[0;36mfindHands\u001b[0;34m(self, img, draw)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfindHands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mimgRGB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgRGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;31m# print(results.multi_hand_landmarks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/RCP/lib/python3.8/site-packages/mediapipe/python/solutions/hands.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \"\"\"\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/RCP/lib/python3.8/site-packages/mediapipe/python/solution_base.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    332\u001b[0m                                      data).at(self._simulated_timestamp))\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_until_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m     \u001b[0;31m# Create a NamedTuple object where the field names are mapping to the graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;31m# output stream names.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pTime = 0\n",
    "cTime = 0\n",
    "cap = cv2.VideoCapture(0)\n",
    "detector = handDetector()\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    img = detector.findHands(img)\n",
    "    all_lmlist, hand_count = detector.findPosition(img)\n",
    "    if len(all_lmlist) != 0:\n",
    "        print(\"timestamp:\", datetime.now().time())\n",
    "#         print(all_lmlist)\n",
    "        print(\"number of hands detected:\", hand_count)\n",
    "        for lmlist in all_lmlist:\n",
    "            print(\"hand coordinates\", [lmlist[4][1], lmlist[4][2]])\n",
    "        print(\"\\n\")\n",
    "\n",
    "    cTime = time.time()\n",
    "    fps = 1 / (cTime - pTime)\n",
    "    pTime = cTime\n",
    "    \n",
    "    cv2.putText(img, str(int(fps)), (10, 70), cv2.FONT_HERSHEY_PLAIN, 3, (0, 0, 0), 3)\n",
    "\n",
    "    cv2.imshow(\"Image\", img)\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pTime = 0\n",
    "# cTime = 0\n",
    "# cap = cv2.VideoCapture(0)\n",
    "# detector = handDetector()\n",
    "\n",
    "# while True:\n",
    "#     success, frame = cap.read()\n",
    "#     img = detector.findHands(frame)\n",
    "#     all_lmlist, hand_count = detector.findPosition(img)\n",
    "#     if len(all_lmlist) != 0:\n",
    "#         print(\"timestamp:\", datetime.now().time())\n",
    "# #         print(all_lmlist)\n",
    "#         print(\"number of hands detected:\", hand_count)\n",
    "#         for lmlist in all_lmlist:\n",
    "#             print(\"hand coordinates\", [lmlist[4][1], lmlist[4][2]])\n",
    "#         print(\"\\n\")\n",
    "\n",
    "#     cTime = time.time()\n",
    "#     fps = 1 / (cTime - pTime)\n",
    "#     pTime = cTime\n",
    "    \n",
    "#     cv2.putText(img, str(int(fps)), (10, 70), cv2.FONT_HERSHEY_PLAIN, 3, (0, 0, 0), 3)\n",
    "\n",
    "#     cv2.imshow(\"Image\", img)\n",
    "#     cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "# hand_detector = handDetector()\n",
    "# while True:\n",
    "#     success, img = cap.read()\n",
    "#     img = hand_detector.findHands(img)\n",
    "#     cv2.imshow(\"Image\", img)\n",
    "#     cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ball Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from imutils.video import VideoStream\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import imutils\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "vs = VideoStream(src=0).start()\n",
    "cap = cv2.VideoCapture(0)\n",
    "pTime = 0\n",
    "cTime = 0\n",
    "hand_detector = handDetector()\n",
    "purpleLower = (128,0,128)\n",
    "purpleUpper = (216,191,216)\n",
    "yellowLower = (22, 93, 0)\n",
    "yellowUpper = (45, 255, 255)\n",
    "pts = deque(maxlen=5)\n",
    "while True:\n",
    "    # grab the current frame\n",
    "    success, frame = cap.read()\n",
    "    img = hand_detector.findHands(frame)\n",
    "#     cv2.imshow(\"Image\", img)\n",
    "#     cv2.waitKey(1)\n",
    "    \n",
    "    if frame is None:\n",
    "        break\n",
    "    # resize the frame, blur it, and convert it to the HSV\n",
    "    # color space\n",
    "    frame = imutils.resize(frame, width=600)\n",
    "    blurred = cv2.GaussianBlur(frame, (11, 11), 0)\n",
    "    hsv = cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # construct a mask for the color \"purple\", then perform\n",
    "    # a series of dilations and erosions to remove any small\n",
    "    # blobs left in the mask\n",
    "    mask1 = cv2.inRange(hsv, purpleLower, purpleUpper)\n",
    "    mask2 = cv2.inRange(hsv, yellowLower, yellowUpper)\n",
    "    mask = cv2.bitwise_or(mask1, mask2)\n",
    "    mask = cv2.erode(mask, None, iterations=2)\n",
    "    mask = cv2.dilate(mask, None, iterations=2)\n",
    "    \n",
    "    # find contours in the mask and initialize the current\n",
    "    # (x, y) center of the ball\n",
    "    cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,\n",
    "        cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    center = None\n",
    "\n",
    "    # only proceed if at least one contour was found\n",
    "    if len(cnts) > 0:\n",
    "        # find the largest contour in the mask, then use\n",
    "        # it to compute the minimum enclosing circle and\n",
    "        # centroid\n",
    "        c = max(cnts, key=cv2.contourArea)\n",
    "        ((x, y), radius) = cv2.minEnclosingCircle(c)\n",
    "        M = cv2.moments(c)\n",
    "        center = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
    "\n",
    "        # only proceed if the radius meets a minimum size\n",
    "        if radius > 20:\n",
    "            # draw the circle and centroid on the frame,\n",
    "            # then update the list of tracked points\n",
    "            cv2.circle(frame, (int(x), int(y)), int(radius),\n",
    "                (0, 255, 255), 2)\n",
    "            cv2.circle(frame, center, 5, (0, 0, 255), -1)\n",
    "\n",
    "    # update the points queue\n",
    "    pts.appendleft(center)\n",
    "\n",
    "    # loop over the set of tracked points\n",
    "    for i in range(1, len(pts)):\n",
    "        # if either of the tracked points are None, ignore\n",
    "        # them\n",
    "        if pts[i - 1] is None or pts[i] is None:\n",
    "            continue\n",
    "\n",
    "        # otherwise, compute the thickness of the line and\n",
    "        # draw the connecting lines\n",
    "        thickness = 1\n",
    "        cv2.line(frame, pts[i - 1], pts[i], (0, 0, 255), thickness)\n",
    "\n",
    "    all_lmlist, hand_count = hand_detector.findPosition(img)\n",
    "        \n",
    "    if len(all_lmlist) != 0:\n",
    "        print(\"timestamp:\", datetime.now().time())\n",
    "#         print(all_lmlist)\n",
    "        print(\"number of hands detected:\", hand_count)\n",
    "        for lmlist in all_lmlist:\n",
    "            print(\"hand coordinates\", [lmlist[4][1], lmlist[4][2]])\n",
    "        print(\"\\n\")\n",
    "\n",
    "    cTime = time.time()\n",
    "    fps = 1 / (cTime - pTime)\n",
    "    pTime = cTime\n",
    "    \n",
    "    cv2.putText(img, str(int(fps)), (10, 70), cv2.FONT_HERSHEY_PLAIN, 3, (0, 0, 0), 3)\n",
    "\n",
    "    cv2.imshow(\"Image\", frame)\n",
    "#     cv2.waitKey(1)\n",
    "#     # show the frame to our screen\n",
    "#     cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "   \n",
    "    # if the 'q' key is pressed, stop the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accelerometer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
